import argparse
from tqdm import tqdm
import os
import json
import traceback

# ÂºïÁî®Ê®°ÁµÑ
from src.agent.init_agent import init_agent
from src.config_utils.table_utils import prepare_game_description, prepare_agent_config
from src.dirs import LOG_PATH
from src.game import RepeatedTableGame
from src.evaluation import DecisionStatistics
from src.utils import TwoAgentsLogger, save_readable_config, get_bedrock_client

# ===========================
# 1. Âü∫Á§éË®≠ÂÆö (Templates)
# ===========================

game_basic_config = {
    "name": "prisoner_dilemma", 
    "n_steps": 5,  # ‰øùÊåÅ 5 ÂõûÂêà‰ª•ÁØÄÁúÅÊàêÊú¨
    "need_check_emotions": True,
    "need_demonstrate_emotions": False,
    "memorize_seen_emotions": False,
    "memorize_demonstrated_emotions": False,
}

naming_config = {
    "currency": "dollars",
    "coplayer": "coplayer",
    "move1": "J", # Âêà‰Ωú
    "move2": "F", # ËÉåÂèõ
}

# Agent 1 (LLM) - È†êË®≠ÂÄºÔºåÁ®çÂæåÊúÉÂú®Ëø¥Âúà‰∏≠Ë¢´Ë¶ÜËìã
agent1_basic_config = {
    "agent_name": "emotion_reflection_llm",
    "llm_name": "placeholder", 
    "has_emotion": False,
    "emotion": "",
    "do_scratchpad_step": False,
    "memory_update_addintional_keys": {
        'currency': naming_config["currency"]
    },
    "game_setting": {
        "round_question": "round_question",
        "general_template": "basic_template", 
        "environment": "experiment", 
        "emotions_info": "with_emotions_affect", 
        "final_instruction": "instruction",
    },
}

# Agent 2 (Rule-based: Tit-for-Tat)
agent2_basic_config = {
    "agent_name": "imitative", #alterating
    "llm_name": "rule_based", 
    "has_emotion": False,
    "emotion": "none",
    "memory_update_addintional_keys": {
        'currency': naming_config["currency"]
    },
}

# ===========================
# 2. Âü∑Ë°åÈÇèËºØ
# ===========================

def run_game(game_config, naming_config, agent1_config, agent2_config, logger):
    game = RepeatedTableGame(
        reward_map=game_config["reward_map"],
        n_steps=game_config["n_steps"],
        need_check_emotions=game_config["need_check_emotions"],
        need_demonstrate_emotions=game_config["need_demonstrate_emotions"],
        memorize_demonstrated_emotions=game_config["memorize_demonstrated_emotions"],
        memorize_seen_emotions=game_config["memorize_seen_emotions"],
    )

    agent1 = init_agent(agent1_config["agent_name"], agent1_config)
    agent2 = init_agent(agent2_config["agent_name"], agent2_config)

    full_config = {
        "game_config": game_config,
        "naming_config": naming_config,
        "agent1_config": agent1_config,
        "agent2_config": agent2_config
    }
    logger.log_json({"config": full_config})
    # ÂÖºÂÆπÂàÜÊûêÁ®ãÂºè
    logger.log_json({"agent1_config": agent1_config}) 

    game.run(agent1, agent2, logger)


if __name__ == "__main__":
    
    # ==========================================
    # 0. AWS Bedrock ÂàùÂßãÂåñÔºàÊé°Áî®ÊàëÁöÑÂª∫Ë≠∞Ôºâ
    # ==========================================
    print("üîß Initializing AWS Bedrock client...")
    get_bedrock_client()  # ÊèêÂâçÈ©óË≠âÊÜëË≠â
    print("‚úÖ Bedrock client ready.\n")
    
    # ==========================================
    # 1. Dry Run ÈñãÈóúÔºàÊé°Áî®ÊàëÁöÑÂª∫Ë≠∞Ôºâ
    # ==========================================
    DRY_RUN = False  # ÊîπÁÇ∫ True ÂèØÈ©óË≠â config
    
    # ==========================================
    # 2. ÊâπÈáèÊ∏¨Ë©¶Ë®≠ÂÆöÔºà‰øùÁïôÊÇ®ÁöÑÁâàÊú¨Ôºâ
    # ==========================================
    llm_name_range = [
        "mistral.mistral-7b-instruct-v0:2",
        #"mistral.mixtral-8x7b-instruct-v0:1",
        #"meta.llama3-8b-instruct-v1:0",       # Llama 3 8B (US Profile, Ëã•‰∏äÈù¢ÈÇ£ÂÄãÂ§±ÊïóÈÄöÂ∏∏ÈÄôÂÄãÊúÉÊàêÂäü)
        #"us.meta.llama3-1-70b-instruct-v1:0",
        #"amazon.titan-text-lite-v1",
        #"amazon.titan-text-express-v1",          # Amazon Titan (Â∞èÂûã/ÈñâÊ∫ê)
        #"openai.gpt-oss-20b-1:0", # 
        #"openai.gpt-oss-120b-1:0", 
        #"us.anthropic.claude-3-7-sonnet-20250219-v1:0",
        #"anthropic.claude-3-5-sonnet-20240620-v1:0", 
        #"cohere.command-r-v1:0",          # Cohere Command R (‰∏çÂêåÊû∂Êßã)
    ]
    
    experiments = [
        ("anger/simple", True),
        ("happiness/simple", True),
        ("no_emotion", False)
    ]
    
    # ==========================================
    # 3. Dry Run È©óË≠âÔºàÊé°Áî®ÊàëÁöÑÂª∫Ë≠∞Ôºå‰ΩÜÁî®ÊÇ®ÁöÑËø¥ÂúàÈÇèËºØÔºâ
    # ==========================================
    if DRY_RUN:
        print(f"üîç DRY RUN MODE")
        print(f"Total Models: {len(llm_name_range)}")
        print(f"Experiments per Model: {len(experiments)}")
        print(f"Total Experiments: {len(llm_name_range) * len(experiments)}\n")
        
        # Ê®°Êì¨Á¨¨‰∏ÄÁµÑÂØ¶È©óÁöÑ config
        test_model = llm_name_range[0]
        test_emotion, test_has_emotion = experiments[0]
        
        current_agent1 = agent1_basic_config.copy()
        current_agent1["llm_name"] = test_model
        current_agent1["has_emotion"] = test_has_emotion
        current_agent1["emotion"] = test_emotion if test_has_emotion else ""
        
        final_game_config = prepare_game_description(game_basic_config, naming_config)
        final_agent1_config = prepare_agent_config(current_agent1, final_game_config["name"], naming_config, 1)
        final_agent1_config["emotion"] = test_emotion if test_has_emotion else ""  # ÊÇ®ÁöÑ‰øÆÊ≠£
        
        final_agent2_config = prepare_agent_config(agent2_basic_config, final_game_config["name"], naming_config, 2)
        
        print("="*60)
        print("First Experiment Config Preview:")
        print("="*60)
        print(f"Game: {final_game_config['name']}")
        print(f"\n--- Agent 1 (LLM) ---")
        print(f"  Model: {final_agent1_config['llm_name']}")
        print(f"  Emotion: {final_agent1_config['emotion']}")
        print(f"\n--- Agent 2 (Rule-based) ---")
        print(f"  Name: {final_agent2_config['agent_name']}")
        print(f"  Ego Move: {final_agent2_config.get('ego_move', 'N/A')}")
        print(f"  Coop Move: {final_agent2_config.get('coop_move', 'N/A')}")
        print("="*60)
        print("\n‚úÖ Dry run complete. Set DRY_RUN=False to execute.")
        exit(0)
    
    # ==========================================
    # 4. Ê≠£ÂºèÂØ¶È©óÔºà‰øùÁïôÊÇ®ÁöÑÁâàÊú¨Ôºâ
    # ==========================================
    print(f"üìã Total Models to Test: {len(llm_name_range)}")
    print(f"üìã Total Emotions per Model: {len(experiments)}")
    print("="*60)

    for model_idx, target_llm in enumerate(llm_name_range):
        print(f"\nüöÄ [{model_idx+1}/{len(llm_name_range)}] Starting Experiments for Model: {target_llm}")
        
        try:
            for emotion_name, has_emotion_flag in tqdm(experiments, desc=f"Testing {target_llm.split('.')[1] if '.' in target_llm else target_llm}"):
                
                # 1. Ë§áË£Ω‰∏¶Ë®≠ÂÆö Agent 1
                current_agent1 = agent1_basic_config.copy()
                current_agent1["llm_name"] = target_llm
                current_agent1["has_emotion"] = has_emotion_flag
                current_agent1["emotion"] = emotion_name if has_emotion_flag else ""
                
                # 2. Ê∫ñÂÇôÈÅäÊà≤Ë®≠ÂÆö
                final_game_config = prepare_game_description(
                    config=game_basic_config, 
                    naming_config=naming_config
                )
                
                # 3. Ê∫ñÂÇô Agent 1 (ËÆÄÂèñ Prompt)
                final_agent1_config = prepare_agent_config(
                    config=current_agent1,
                    game_name=final_game_config["name"],
                    naming_config=naming_config,
                    agent_ind=1,
                )
                
                # ======================================================
                # [ÈóúÈçµ‰øÆÊ≠£] Âº∑Âà∂Â∞á emotion Â≠ó‰∏≤ÂØ´ÂõûË®≠ÂÆöÊ™îÔºå‰ª•ÂÖçË¢´ prepare ÂáΩÂºèÂºÑ‰∏ü
                # ======================================================
                final_agent1_config["emotion"] = emotion_name if has_emotion_flag else ""
                # ======================================================
                
                # 4. Ê∫ñÂÇô Agent 2
                final_agent2_config = prepare_agent_config(
                    config=agent2_basic_config,
                    game_name=final_game_config["name"],
                    naming_config=naming_config,
                    agent_ind=2,
                )
                
                # 5. ÂàùÂßãÂåñ Logger
                # ÂæûÊ®°ÂûãÂêçÁ®±ÊèêÂèñÁ∞°Áü≠ÁâàÊú¨ (‰æãÂ¶Ç "meta.llama3-8b-instruct-v1:0" -> "llama3-8b")
                model_short_name = target_llm.split('.')[-1].split('-instruct')[0].split('-v')[0]
                logger = TwoAgentsLogger.construct_from_configs(
                    final_agent1_config, 
                    final_agent2_config, 
                    LOG_PATH, 
                    game_name=final_game_config['name'],
                    model_suffix=model_short_name
                )
                
                # 6. Âü∑Ë°åÈÅäÊà≤
                run_game(final_game_config, naming_config, final_agent1_config, final_agent2_config, logger)
                
                # 7. Áµ±Ë®à
                evaluate_statistics = DecisionStatistics(logger.run_name, LOG_PATH)
                decision_stats, count_combinations = evaluate_statistics.get_metric()
                
                save_readable_config(
                    {"decision_stats": decision_stats, "count_combinations": count_combinations},
                    logger.run_name,
                    LOG_PATH,
                )

        except Exception as e:
            print(f"\n‚ùå Critical Error with model {target_llm}: {str(e)}")
            print("Skipping to next model...")
            traceback.print_exc()  # Âª∫Ë≠∞ÊâìÈñã‰ª•‰æø debug

    print("\n" + "="*60)
    print("‚úÖ All experiments finished!")
